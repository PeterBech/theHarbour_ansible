# Harbour â€“ k3s Homelab Cluster âš“

Harbour er mit lille **k3s-homelab cluster**, bygget pÃ¥ Lenovo M700-maskiner.
Tanken er et simpelt, stabilt setup, der er let at automatisere med **Ansible**, og som kan udvides lÃ¸bende med services som Ingress, cert-manager, storage m.m.

Clusteret er navngivet efter et havne-tema, hvor Ã©n node fungerer som fyrtÃ¥rn (control-plane), og de Ã¸vrige som dokker, der hÃ¥ndterer lasten.

---

## ğŸ§­ Overblik

* **Cluster-navn:** `harbour`
* **Kubernetes distribution:** k3s
* **Provisionering:** Ansible
* **Admin-miljÃ¸:** WSL (Ubuntu)

---

## âš“ Node-navngivning & IP-plan

| Rolle         | Hostname             | IP-adresse      | Hardware                   | S/N      |
| ------------- | -------------------- | --------------- | -------------------------- | -------- |
| Control-plane | `harbour-lighthouse` | `192.168.164.2` | i3 Â· 4 GB RAM Â· 256 GB SSD |          |
| Worker        | `harbour-dock-1`     | `192.168.164.3` | i3 Â· 8 GB RAM Â· 128 GB SSD | S4BV7172 |
| Worker        | `harbour-dock-2`     | `192.168.164.4` | i3 Â· 8 GB RAM Â· 128 GB SSD | S4BA1778 |

`harbour-lighthouse` fungerer som master / control-plane og kÃ¸rer k3s-serveren.

---

## ğŸ“ Repository-struktur

```text
ansible/
â”œâ”€ collections/
â”‚  â””â”€ requirements.yml
â”œâ”€ Inventory/
â”‚  â”œâ”€ group_vars
â”‚  â”‚  â””â”€ all.yml
â”‚  â””â”€ inventory.yml
â”œâ”€ playbooks/
â”‚  â”œâ”€ breakdown.yml
â”‚  â”œâ”€ build.yml
â”‚  â””â”€ first_run.yml
â””â”€ roles/
   â””â”€ common/
      â”œâ”€ defaults/
      â”‚  â””â”€ main.yml
      â””â”€ tasks/
         â””â”€ main.yml
s
```

> BemÃ¦rk: `Inventory` har stort **I** (Linux er case-sensitive i WSL).

---

## ğŸ”‘ FÃ¸rste opsÃ¦tning fra WSL (SSH + Ansible)

### 1ï¸âƒ£ GenerÃ©r SSH-nÃ¸gle

```bash
ssh-keygen -t ed25519 -C "harbour-homelab"
```

Tryk **Enter** for standard placering:

```
~/.ssh/id_ed25519
```

---

### 2ï¸âƒ£ KopiÃ©r SSH-nÃ¸glen til alle noder

```bash
ssh-copy-id pbech@192.168.164.2
ssh-copy-id pbech@192.168.164.3
ssh-copy-id pbech@192.168.164.4
```

Test adgang:

```bash
ssh pbech@harbour-lighthouse
```

---

### 3ï¸âƒ£ InstallÃ©r Ansible i WSL (pipx)

```bash
sudo apt update
sudo apt install -y pipx
pipx ensurepath
source ~/.bashrc
pipx install ansible-core
```

VerificÃ©r:

```bash
ansible --version
```

---

### 4ï¸âƒ£ Ansible inventory

**Fil:** `ansible/Inventory/hosts.yml`

```yaml
all:
  children:
    k3s_master:
      hosts:
        harbour-lighthouse:
          ansible_host: 192.168.164.2
    k3s_workers:
      hosts:
        harbour-dock-1:
          ansible_host: 192.168.164.3
        harbour-dock-2:
          ansible_host: 192.168.164.4
  vars:
    ansible_user: pbech
```

---

### 5ï¸âƒ£ Test Ansible-forbindelse

```bash
ansible all \
  -i "/mnt/c/Users/pibm9/Documents/K3s cluster/ansible/Inventory" \
  -m ping
```

Forventet output:

```text
harbour-dock-1 | SUCCESS => pong
harbour-dock-2 | SUCCESS => pong
harbour-lighthouse | SUCCESS => pong
```

---

### 6ï¸âƒ£ KÃ¸r build-playbook

```bash
cd "/mnt/c/Users/pibm9/Documents/K3s cluster/ansible"
ansible-playbook -i Inventory playbooks/first_run.yml
# Hvis den beder om sudo-password, kÃ¸r denne:
# ansible-playbook -i Inventory playbooks/build.yml --ask-pass -e "ansible_become_password={Password}"

# Hvis den ikke kan finde /common, sÃ¥ kÃ¸r denne:
# ANSIBLE_ROLES_PATH=./roles ansible-playbook -i Inventory playbooks/first_run.yml --ask-pass -e "ansible_become_password={ Password }"
```

Playbooken forventes at:

* installere basispakker
* konfigurere systemet (UFW, swap off, logging)
* installere k3s server pÃ¥ `harbour-lighthouse`
* installere k3s agents pÃ¥ `harbour-dock-*`

---

## âœ… Efter installation

```bash
kubectl get nodes
```

Forventet output:

```text
harbour-lighthouse   Ready   control-plane
harbour-dock-1       Ready   worker
harbour-dock-2       Ready   worker
```

---

## ğŸ§± High Availability-strategi

Harbour er designet med **pragmatisk HA** i fokus.

* Single control-plane (`harbour-lighthouse`)
* HA workloads pÃ¥ worker-noder
* Ingen workloads pÃ¥ control-plane

**Principper**

* `replicas: 2` for kritiske services
* Pod anti-affinity mellem workers
* Replikeret storage (Longhorn, RF=2)

> Ã†gte HA control-plane krÃ¦ver minimum 3 control-plane noder og er uden for nuvÃ¦rende scope.

---

## ğŸ—ºï¸ Roadmap

1. k3s + Ansible bootstrap âœ…
2. MetalLB
3. Pi-hole + Unbound
4. Tailscale
5. Monitoring (Prometheus / Grafana)
6. Persistent storage (Longhorn)
7. Nextcloud
8. Hardening, backups & dokumentation

---

> *Denne README fungerer som levende dokumentation og opdateres lÃ¸bende.* âš“
